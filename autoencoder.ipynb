{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, losses, Model\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "# Paths\n",
    "#test_augmentation\n",
    "original_dir = \"/home/mahdi/logo_detection_model/autoencoder/detected_logos/\"\n",
    "train_dir = \"/home/mahdi/logo_detection_model/autoencoder/train\"\n",
    "val_dir = \"/home/mahdi/logo_detection_model/autoencoder/validation\"\n",
    "\n",
    "# Split data into train and validation sets\n",
    "for class_name in os.listdir(original_dir):\n",
    "    class_path = os.path.join(original_dir, class_name)\n",
    "    train_class_path = os.path.join(train_dir, class_name)\n",
    "    val_class_path = os.path.join(val_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_class_path, exist_ok=True)\n",
    "    os.makedirs(val_class_path, exist_ok=True)\n",
    "\n",
    "    images = os.listdir(class_path)\n",
    "    split_idx = int(len(images) * 0.8)  # 80% for training, 20% for validation\n",
    "\n",
    "    for img_name in images[:split_idx]:\n",
    "        shutil.copy(os.path.join(class_path, img_name), train_class_path)\n",
    "    for img_name in images[split_idx:]:\n",
    "        shutil.copy(os.path.join(class_path, img_name), val_class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# base_dir = \"/home/mahdi/logo_detection_model/autoencoder/detected_logos/\"\n",
    "# dummy_dir = os.path.join(base_dir, \"dummy_class\")\n",
    "\n",
    "# os.makedirs(dummy_dir, exist_ok=True)\n",
    "\n",
    "# for file_name in os.listdir(base_dir):\n",
    "#     file_path = os.path.join(base_dir, file_name)\n",
    "#     if os.path.isfile(file_path):  # Skip directories\n",
    "#         shutil.move(file_path, dummy_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 258 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     dir,  # Path to training data\n",
    "#     target_size=(224, 224),  # Resize images\n",
    "#     batch_size=32,  # Batch size\n",
    "#     class_mode=None,  # No class labels, input is also output\n",
    "#     subset=\"training\"  # Training split\n",
    "# )\n",
    "\n",
    "# val_generator = val_datagen.flow_from_directory(\n",
    "#     dir,  # Path to validation data\n",
    "#     target_size=(224, 224),  # Resize images\n",
    "#     batch_size=32,  # Batch size\n",
    "#     class_mode=None,  # No class labels, input is also output\n",
    "#     subset=\"validation\"  # Validation split\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images belonging to 1 classes.\n",
      "Found 7 images belonging to 1 classes.\n",
      "Training samples: 13\n",
      "Validation samples: 7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = \"/home/mahdi/logo_detection_model/autoencoder/train\"\n",
    "val_dir = \"/home/mahdi/logo_detection_model/autoencoder/validation\"\n",
    "dir = \"/home/mahdi/logo_detection_model/autoencoder/detected_logos/\"\n",
    "\n",
    "\n",
    "def safe_preprocess(img):\n",
    "    try:\n",
    "        return img  # Pass through valid images\n",
    "    except Exception as e:\n",
    "        print(\"Skipping corrupted image.\")\n",
    "        return np.zeros((224, 224, 3))  # Placeholder for invalid images\n",
    "\n",
    "\n",
    "# Training Data Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values\n",
    "    # validation_split=0.2\n",
    "    preprocessing_function=safe_preprocess\n",
    ")\n",
    "\n",
    "# Validation Data Generator\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values\n",
    "    # validation_split=0.2\n",
    "    preprocessing_function=safe_preprocess\n",
    ")\n",
    "\n",
    "# Create Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Path to training data\n",
    "    target_size=(224, 224),  # Resize images\n",
    "    # batch_size=4,  # Batch size\n",
    "    class_mode=None  # No class labels, input is also output\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "     val_dir,  # Path to validation data\n",
    "    target_size=(224, 224),  # Resize images\n",
    "    # batch_size=4,  # Batch size\n",
    "    class_mode=None  # No class labels, input is also output\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train generator samples: 13\n",
      "Validation generator samples: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train generator samples: {train_generator.samples}\")\n",
    "print(f\"Validation generator samples: {val_generator.samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shapes: [(224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3), (224, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Try fetching a batch of data\n",
    "batch = next(iter(train_generator))\n",
    "print(\"Train batch shapes:\", [x.shape for x in batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: (7, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/logo_detection_model/.venv/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_generator))\n",
    "print(f\"Input batch shape: {batch.shape}\")  # Should match (batch_size, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Autoencoder architecture\n",
    "# def build_autoencoder(input_shape=(224, 224, 3), latent_dim=128):\n",
    "#     # Encoder\n",
    "#     input_img = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "#     x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "#     x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "#     x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "#     x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     latent = layers.Dense(latent_dim, activation=\"relu\")(x)  # Latent space\n",
    "\n",
    "#     # Decoder\n",
    "#     x = layers.Dense(28 * 28 * 128, activation=\"relu\")(latent)\n",
    "#     x = layers.Reshape((28, 28, 128))(x)\n",
    "#     x = layers.Conv2DTranspose(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "#     x = layers.UpSampling2D((2, 2))(x)\n",
    "#     x = layers.Conv2DTranspose(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "#     x = layers.UpSampling2D((2, 2))(x)\n",
    "#     output_img = layers.Conv2DTranspose(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "#     # Autoencoder Model\n",
    "#     autoencoder = models.Model(input_img, output_img)\n",
    "#     encoder = models.Model(input_img, latent)  # Separate encoder model for feature extraction\n",
    "\n",
    "#     return autoencoder, encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,731</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_6 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_7 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │         \u001b[38;5;34m1,731\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m84\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">298,839</span> (1.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m298,839\u001b[0m (1.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">298,839</span> (1.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m298,839\u001b[0m (1.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(224, 224, 3))\n",
    "x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(encoder_input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)  # Down to (112, 112, 64)\n",
    "x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)  # Down to (56, 56, 128)\n",
    "encoder_output = x\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(encoder_output)\n",
    "x = layers.UpSampling2D((2, 2))(x)  # Up to (112, 112, 128)\n",
    "x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)  # Up to (224, 224, 64)\n",
    "decoder_output = layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)  # Match input shape\n",
    "\n",
    "# Autoencoder Model\n",
    "decoder_output = layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(decoder_output)\n",
    "autoencoder = Model(encoder_input, decoder_output)\n",
    "autoencoder = models.Model(encoder_input, decoder_output)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build and compile the autoencoder\n",
    "# autoencoder, encoder = build_autoencoder()\n",
    "# autoencoder.compile(optimizer=\"adam\", loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder input shape: (None, 224, 224, 3)\n",
      "Autoencoder output shape: (None, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Autoencoder input shape:\", autoencoder.input_shape)\n",
    "print(\"Autoencoder output shape:\", autoencoder.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 0, Validation steps: 0\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = val_generator.samples // val_generator.batch_size\n",
    "print(f\"Steps per epoch: {steps_per_epoch}, Validation steps: {validation_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generators\n",
    "assert train_generator.samples > 0, \"Training directory is empty or misconfigured!\"\n",
    "assert val_generator.samples > 0, \"Validation directory is empty or misconfigured!\"\n",
    "\n",
    "steps_per_epoch = max(1, train_generator.samples // train_generator.batch_size)\n",
    "validation_steps = max(1, val_generator.samples // val_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.12/site-packages (from opencv-python) (2.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "all_images = []\n",
    "img_list = glob.glob('/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3171_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/731_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4925_21.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/971_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1007_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1133_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1082_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2533_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3067_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3162_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5138_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5196_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/386_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4852_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/835_29.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1742_37.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1535_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/476_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3092_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4897_16.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/31.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3127_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4236_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3093_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/569_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2099_41.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2931_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5229_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1368_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5191_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4644_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2551_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2171_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1406_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4873_20.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1215_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4777_40.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2438_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2803_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1498_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2941_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/739_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1453_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2046_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2006_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/980_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/314_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3408_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2239_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4615_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3862_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3179_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5233_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/364_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1140_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5095_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/316_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4719_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1116_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1066_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1003_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3273_20.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3949_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4685_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3081_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4748_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1471_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4258_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4404_20.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3673_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1705_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4026_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1522_20.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1672_12.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/721_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3481_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3124_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1024_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1884_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/571_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2085_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4713_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4716_31.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2304_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/476_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/361_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4229_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1696_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4261_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3619_26.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2448_27.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1841_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/422_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1714_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4718_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/515_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1272_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4588_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/13.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4470_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/21.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1938_20.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1878_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5352_14.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3288_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2464_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/15.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/413_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4341_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1846_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2243_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/34.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1847_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2294_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4227_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5173_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1661_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1074_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1416_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/709_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4584_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1450_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2877_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2924_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3624_252.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1259_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5314_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1046_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/685_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5358_22.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2214_28.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2789_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2134_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2973_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1507_35.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4350_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/374_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2008_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3387_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/371_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4991_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3524_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4631_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/346_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/556_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3758_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3176_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/975_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2246_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2529_19.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/701_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/309_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3382_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3229_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/611_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4643_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2648_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1111_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4682_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/33.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1500_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1778_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5269_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4527_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2436_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5010_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2796_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1424_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/711_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1523_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5106_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5121_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3094_27.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1972_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3554_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1111_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/439_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4641_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2284_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2067_11.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1700_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5137_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1857_14.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4427_30.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4252_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5195_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5320_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/517_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1415_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1987_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1437_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3327_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2187_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4959_19.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/310_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4927_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/401_27.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5334_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2787_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/263_14.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/17.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5169_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1732_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2249_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/452_8.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/412_17.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3559_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4731_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4769_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5139_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2126_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/14.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4627_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2900_13.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3114_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2967_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2460_10.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3161_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4851_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2545_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2654_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4225_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3670_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1001_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1880_12.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/499_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2261_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4418_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2145_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/570_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/29.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/399_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/16.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/401_28.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/702_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4337_50.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/212_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/349_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1382_13.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4257_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4963_37.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/36.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2227_9.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/322_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/5339_21.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3938_1.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1962_6.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1294_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3443_4.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/3731_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/4553_2.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/2245_5.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/528_3.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1361_7.jpg', '/home/mahdi/logo_detection_model/autoencoder/detected_logos/logo_images/1345_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 119400 into shape (224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# img = img.astype('float32') / 255.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     all_images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m      6\u001b[0m all_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_images)\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:299\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 119400 into shape (224,224,3)"
     ]
    }
   ],
   "source": [
    "for image in img_list:\n",
    "    img = cv2.imread(image,0)\n",
    "    # img = img.astype('float32') / 255.\n",
    "    img = np.reshape(img,(224,224,3))\n",
    "    all_images.append(img)\n",
    "all_images = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When providing `x` as a PyDataset, `y` should not be passed. Instead, the targets should be included as part of the PyDataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the autoencoder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/__init__.py:129\u001b[0m, in \u001b[0;36mraise_unsupported_arg\u001b[0;34m(arg_name, arg_description, input_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_unsupported_arg\u001b[39m(arg_name, arg_description, input_type):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen providing `x` as a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould not be passed. Instead, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe included as part of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: When providing `x` as a PyDataset, `y` should not be passed. Instead, the targets should be included as part of the PyDataset."
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    train_generator,train_generator,\n",
    "    validation_data= (val_generator,val_generator ),\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (13, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Debug the data generators\n",
    "batch = next(iter(train_generator))\n",
    "print(f\"Batch shape: {batch.shape if batch is not None else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 1\n",
      "Validation steps: 1\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = max(1, train_generator.samples // train_generator.batch_size)\n",
    "validation_steps = max(1, val_generator.samples // val_generator.batch_size)\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: (13, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_generator))\n",
    "print(f\"Train batch shape: {batch.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation batch shape: (7, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/logo_detection_model/.venv/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_generator))\n",
    "print(f\"Validation batch shape: {batch.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "Prediction shape: (7, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "predictions = autoencoder.predict(batch)\n",
    "print(f\"Prediction shape: {predictions.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (13, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_generator))\n",
    "predictions = autoencoder(batch)\n",
    "print(f\"Prediction shape: {predictions.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size),\n",
    "    validation_steps=max(1, val_generator.samples // val_generator.batch_size),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the autoencoder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# steps_per_epoch=len(train_generator),\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_steps=len(val_generator)\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/logo_detection_model/.venv/lib/python3.12/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    batch_size = 4,\n",
    "    # steps_per_epoch=len(train_generator),\n",
    "    # validation_steps=len(val_generator)\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoder for feature extraction\n",
    "encoder.save(\"logo_encoder.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similarity using latent features\n",
    "def calculate_similarity(encoder, input_logo, valid_logos):\n",
    "    input_features = encoder.predict(input_logo)\n",
    "    similarities = []\n",
    "    for valid_logo in valid_logos:\n",
    "        valid_features = encoder.predict(valid_logo)\n",
    "        similarity = np.dot(input_features, valid_features.T) / (\n",
    "            np.linalg.norm(input_features) * np.linalg.norm(valid_features)\n",
    "        )\n",
    "        similarities.append(similarity)\n",
    "    return similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_logo = ...  # Load input image and preprocess\n",
    "valid_logos = [...]  # List of preprocessed valid logos\n",
    "similarities = calculate_similarity(encoder, input_logo, valid_logos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
